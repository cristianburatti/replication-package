{"cells":[{"cell_type":"markdown","metadata":{"id":"caZ61QzceIfi"},"source":["### Creation of the environment"]},{"cell_type":"code","source":["import os\n","os.environ['USE_AUTH_EPHEM'] = '0'"],"metadata":{"id":"3z5H-CyLzhDV","executionInfo":{"status":"ok","timestamp":1652719624359,"user_tz":-120,"elapsed":4,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2h1MRzBLtex2","outputId":"6569f4ac-a242-42c4-ad81-840f2b37954d","executionInfo":{"status":"ok","timestamp":1652719665106,"user_tz":-120,"elapsed":40750,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-22.1\n","Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n","  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-hbwg8uz6\n","  Running command git clone --filter=blob:none --quiet https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-hbwg8uz6\n","  Resolved https://github.com/google-research/text-to-text-transfer-transformer.git to commit b7d861c6b383c97eda6de7dfe5d2867a3c6afd0a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.0.0)\n","Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (2.10.1)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (0.5.3)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (0.5.0)\n","Collecting mesh-tensorflow[transformer]>=0.1.13\n","  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (3.2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.3.5)\n","Collecting rouge-score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.4.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqio-nightly\n","  Downloading seqio_nightly-0.0.7.dev20220516-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.15.0)\n","Collecting tensorflow-text\n","  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tfds-nightly\n","  Downloading tfds_nightly-4.5.2.dev202205160045-py3-none-any.whl (4.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.9.3) (1.11.0+cu113)\n","Collecting transformers>=2.7.0\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.3) (0.16.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.3) (4.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.3) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.9.3) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5==0.9.3) (2.8.2)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5==0.9.3) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5==0.9.3) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5==0.9.3) (1.1.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.3) (0.12.0)\n","Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.3) (2.8.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (1.1.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (5.7.1)\n","Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (3.17.3)\n","Collecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (4.2.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (0.3.4)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.9.3) (1.7.0)\n","Collecting etils[epath-no-tf]\n","  Downloading etils-0.5.1-py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.8/87.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.7.0->t5==0.9.3) (3.0.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.3) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.3) (2.10)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (2.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.1.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.44.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.5.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.14.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.6.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.25.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (14.0.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (57.4.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath-no-tf]->tfds-nightly->t5==0.9.3) (3.8.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.3) (21.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.3) (0.1.7)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly->t5==0.9.3) (1.56.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->t5==0.9.3) (3.2.0)\n","Building wheels for collected packages: t5\n","  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for t5: filename=t5-0.9.3-py3-none-any.whl size=160613 sha256=9ea3dabbb1d559526bd153ade7ab861381b306cd2c1c2bab43299f7d12239c49\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_yfkr8z_/wheels/bf/e8/36/0d7b7d2aa6a91236ea133d24d501fb1faf73d6bf2579f05c96\n","Successfully built t5\n","Installing collected packages: tokenizers, tf-estimator-nightly, sentencepiece, toml, pyyaml, portalocker, etils, colorama, sacrebleu, rouge-score, mesh-tensorflow, huggingface-hub, transformers, tfds-nightly, tensorflow-text, seqio-nightly, t5\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed colorama-0.4.4 etils-0.5.1 huggingface-hub-0.6.0 mesh-tensorflow-0.1.21 portalocker-2.4.0 pyyaml-6.0 rouge-score-0.0.4 sacrebleu-2.0.0 sentencepiece-0.1.96 seqio-nightly-0.0.7.dev20220516 t5-0.9.3 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 tfds-nightly-4.5.2.dev202205160045 tokenizers-0.12.1 toml-0.10.2 transformers-4.19.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRunning on TPU: grpc://10.84.112.146:8470\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["%tensorflow_version 2.x\n","!pip3 install --upgrade pip\n","#!pip install -qU t5\n","!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n","\n","import functools\n","import os\n","import time\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","import tensorflow.compat.v1 as tf\n","tf.flags.DEFINE_string('f','','')\n","\n","import tensorflow_datasets as tfds\n","\n","import t5\n","\n","\n","#Set the base dir(Google cloud bucket)\n","BASE_DIR = \"gs://code-generation\" \n","\n","#C.B.: SEQ_LENGTH for number of tokens\n","SEQ_LENGTH = 512\n","\n","if not BASE_DIR or BASE_DIR == \"gs://\":\n","  raise ValueError(\"You must enter a BASE_DIR.\")\n","ON_CLOUD = True\n","\n","\n","if ON_CLOUD:\n","  import tensorflow_gcs_config\n","  from google.colab import auth\n","  # Set credentials for GCS reading/writing from Colab and TPU.\n","  TPU_TOPOLOGY = \"2x2\"\n","  try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","    TPU_ADDRESS = tpu.get_master()\n","    print('Running on TPU:', TPU_ADDRESS)\n","  except ValueError:\n","    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","  auth.authenticate_user()\n","  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n","  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n","\n","tf.disable_v2_behavior()\n","\n","# Improve logging.\n","from contextlib import contextmanager\n","import logging as py_logging\n","\n","if ON_CLOUD:\n","  tf.get_logger().propagate = False\n","  py_logging.root.setLevel('INFO')\n","\n","@contextmanager\n","def tf_verbosity_level(level):\n","  og_level = tf.logging.get_verbosity()\n","  tf.logging.set_verbosity(level)\n","  yield\n","  tf.logging.set_verbosity(og_level)"]},{"cell_type":"markdown","metadata":{"id":"Gmks3SRxe-Db"},"source":["### Loading of tsv files\n","With this script you can load each tsv file for finetuning.\n","Please be sure that the path to all tsv files are correct"]},{"cell_type":"code","source":["train_construct_length = 251271\n","test__construct_length = 37722\n","\n","train_block_length = 101646\n","test__block_length = 12706\n","\n","train_token_length = 307779\n","test__token_length = 10930"],"metadata":{"id":"rjmIA2pAYtHH","executionInfo":{"status":"ok","timestamp":1652719665106,"user_tz":-120,"elapsed":10,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"glLJUm1dxIiH","executionInfo":{"status":"ok","timestamp":1652719665107,"user_tz":-120,"elapsed":9,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["#Validation(train and test on the same dataset)\n","\n","nq_tsv_path_construct = {\n","    \"train\":      BASE_DIR + '/T5_extension/ft_datasets/construct_train.tsv',\n","    \"validation\": BASE_DIR + '/T5_extension/ft_datasets/construct_test.tsv',\n","}\n","\n","num_nq_examples_construct = dict(train=train_construct_length, validation=test__construct_length)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_-B3_th9eP5y","executionInfo":{"status":"ok","timestamp":1652719665107,"user_tz":-120,"elapsed":8,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["#Validation(train and test on the same dataset)\n","\n","nq_tsv_path_block = {\n","    \"train\":      BASE_DIR + '/T5_extension/ft_datasets/block_train.tsv',\n","    \"validation\": BASE_DIR + '/T5_extension/ft_datasets/block_test.tsv',\n","}\n","\n","num_nq_examples_block = dict(train=train_block_length, validation=test__block_length)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6u7JbyjV8GN3","executionInfo":{"status":"ok","timestamp":1652719665108,"user_tz":-120,"elapsed":8,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["#Validation(train and test on the same dataset)\n","\n","nq_tsv_path_token = {\n","    \"train\":      BASE_DIR + '/T5_extension/ft_datasets/token_train.tsv',\n","    \"validation\": BASE_DIR + '/T5_extension/ft_datasets/token_test.tsv',\n","}\n","\n","num_nq_examples_token = dict(train=train_token_length, validation=test__token_length)"]},{"cell_type":"markdown","metadata":{"id":"cP_BYruSela-"},"source":["### Preprocess of the dataset\n","In this step we preprocess the dataset.  \n","You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n","We're going to preprocess all the tsv file so that T5 can use them for evaluation."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PobLvzL18zzR","executionInfo":{"status":"ok","timestamp":1652719665108,"user_tz":-120,"elapsed":8,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["from t5.data import postprocessors as t5_postprocessors\n","from t5.seqio import Feature,SentencePieceVocabulary\n","\n","\n","# # Set the path of sentencepiece model and vocab files\n","# # Must be the same used for the pre-trained phase\n","vocab_model_path = BASE_DIR + '/T5_extension/code.model'\n","vocab_path = BASE_DIR + '/T5_extension/code.vocab'\n","\n","\n","TaskRegistry = t5.data.TaskRegistry\n","TfdsTask = t5.data.TfdsTask\n","\n","\n","def get_default_vocabulary():\n","  return SentencePieceVocabulary(vocab_model_path, 100)\n","\n","DEFAULT_OUTPUT_FEATURES = {\n","    \"inputs\": Feature(\n","        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n","\n","    \"targets\": Feature(\n","        vocabulary=get_default_vocabulary(), add_eos=True)\n","}"]},{"cell_type":"markdown","metadata":{"id":"mn-DMH5FkSO2"},"source":["JAVA CONSTRUCT"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"K0NTLbyXvkCs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719667560,"user_tz":-120,"elapsed":2459,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"9f6aa48f-2c93-44f0-96a1-1aef37684aef"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few raw train examples...\n","{'input': b'private String formatEventDateRange(Date beginDate, Date endDate) { if ( <extra_id_0>) { if (isEndOfDay(endDate)) { return formatEventDate(beginDate); } else if (isMidnight(beginDate)) { return formatEventDate(beginDate) + \" until \" + eventOutDayOnlyDf.format(endDate); } else { return formatEventDate(beginDate) + \" - \" + eventOutTimeOnlyDf.format(endDate); } } else { return formatEventDate(beginDate) + \" - \" + formatEventDate(endDate); } } <CONST> RSSItem(String, String, String, String, String, String, String, String) <INV> String formatEventDate(Date), boolean isMidnight(Date), boolean isEndOfDay(Date) <OTH> String sanitizeString(String), String sanitizeStringWithTags(String), String getTitle(), String getDescription(), String getLink(), String getAuthor(), String getDate(), URL getImgUrl(), String toString()', 'output': b'DateUtils.isSameDay(beginDate, endDate)'}\n","{'input': b'private String formatEventDateRange(Date beginDate, Date endDate) { if (DateUtils.isSameDay(beginDate, endDate)) { if ( <extra_id_0>) { return formatEventDate(beginDate); } else if (isMidnight(beginDate)) { return formatEventDate(beginDate) + \" until \" + eventOutDayOnlyDf.format(endDate); } else { return formatEventDate(beginDate) + \" - \" + eventOutTimeOnlyDf.format(endDate); } } else { return formatEventDate(beginDate) + \" - \" + formatEventDate(endDate); } } <CONST> RSSItem(String, String, String, String, String, String, String, String) <INV> String formatEventDate(Date), boolean isMidnight(Date) <OTH> String sanitizeString(String), String sanitizeStringWithTags(String), boolean isEndOfDay(Date), String getTitle(), String getDescription(), String getLink(), String getAuthor(), String getDate(), URL getImgUrl(), String toString()', 'output': b'isEndOfDay(endDate)'}\n","{'input': b'private String formatEventDateRange(Date beginDate, Date endDate) { if (DateUtils.isSameDay(beginDate, endDate)) { if (isEndOfDay(endDate)) { return formatEventDate(beginDate); } else if ( <extra_id_0>) { return formatEventDate(beginDate) + \" until \" + eventOutDayOnlyDf.format(endDate); } else { return formatEventDate(beginDate) + \" - \" + eventOutTimeOnlyDf.format(endDate); } } else { return formatEventDate(beginDate) + \" - \" + formatEventDate(endDate); } } <CONST> RSSItem(String, String, String, String, String, String, String, String) <INV> String formatEventDate(Date), boolean isEndOfDay(Date) <OTH> String sanitizeString(String), String sanitizeStringWithTags(String), boolean isMidnight(Date), String getTitle(), String getDescription(), String getLink(), String getAuthor(), String getDate(), URL getImgUrl(), String toString()', 'output': b'isMidnight(beginDate)'}\n","{'input': b'private String formatEventDateRange(Date beginDate, Date endDate) { if (DateUtils.isSameDay(beginDate, endDate)) { if (isEndOfDay(endDate)) { return formatEventDate(beginDate); } else if (isMidnight(beginDate)) { return formatEventDate(beginDate) + \" until \" + eventOutDayOnlyDf.format( <extra_id_0>); } else { return formatEventDate(beginDate) + \" - \" + eventOutTimeOnlyDf.format(endDate); } } else { return formatEventDate(beginDate) + \" - \" + formatEventDate(endDate); } } <CONST> RSSItem(String, String, String, String, String, String, String, String) <INV> String formatEventDate(Date), boolean isMidnight(Date), boolean isEndOfDay(Date) <OTH> String sanitizeString(String), String sanitizeStringWithTags(String), String getTitle(), String getDescription(), String getLink(), String getAuthor(), String getDate(), URL getImgUrl(), String toString()', 'output': b'endDate'}\n","{'input': b'private String formatEventDateRange(Date beginDate, Date endDate) { if (DateUtils.isSameDay(beginDate, endDate)) { if (isEndOfDay(endDate)) { return formatEventDate(beginDate); } else if (isMidnight(beginDate)) { return formatEventDate(beginDate) + \" until \" + eventOutDayOnlyDf.format(endDate); } else { return formatEventDate(beginDate) + \" - \" + eventOutTimeOnlyDf.format( <extra_id_0>); } } else { return formatEventDate(beginDate) + \" - \" + formatEventDate(endDate); } } <CONST> RSSItem(String, String, String, String, String, String, String, String) <INV> String formatEventDate(Date), boolean isMidnight(Date), boolean isEndOfDay(Date) <OTH> String sanitizeString(String), String sanitizeStringWithTags(String), String getTitle(), String getDescription(), String getLink(), String getAuthor(), String getDate(), URL getImgUrl(), String toString()', 'output': b'endDate'}\n"]}],"source":["def nq_construct(split, shuffle_files=True):\n","  # We only have one file for each split.\n","  del shuffle_files\n","\n","   # Load lines from the text file as examples.\n","\n","  ds = tf.data.TextLineDataset(nq_tsv_path_construct[split])\n","  ds = ds.map(\n","      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n","                        field_delim=\"\\t\", use_quote_delim=False),\n","      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","  \n","  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n","  return ds\n","\n","print(\"A few raw train examples...\")\n","for ex in tfds.as_numpy(nq_construct(\"train\").take(5)):\n","  print(ex)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4bJZPQgjxKZ1","executionInfo":{"status":"ok","timestamp":1652719667560,"user_tz":-120,"elapsed":7,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["def construct_preprocessing(ds):\n","  \n","  def to_inputs_and_targets(ex):\n","\n","        inputs = tf.strings.join(['CONSTRUCT:' + ex['input']], separator=' ')\n","        class_label = tf.strings.join([ex['output']], separator=' ')\n","        return {'inputs': inputs, 'targets': class_label }\n","    \n","  return ds.map(to_inputs_and_targets, \n","                num_parallel_calls=tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"h3jAg8Zhx_Ep","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719667561,"user_tz":-120,"elapsed":6,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"2d06eb41-8c7f-4560-a5bf-f2497d20afbb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<t5.data.dataset_providers.FunctionTask at 0x7fb96bdd7710>"]},"metadata":{},"execution_count":10}],"source":["t5.data.TaskRegistry.remove('construct')\n","t5.data.TaskRegistry.add(\n","    \"construct\",\n","    dataset_fn=nq_construct,\n","    splits=[\"train\", \"validation\"],\n","    text_preprocessor=[construct_preprocessing],\n","    output_features = DEFAULT_OUTPUT_FEATURES,\n","    metric_fns=[t5.evaluation.metrics.accuracy],\n","    num_input_examples=num_nq_examples_construct\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"e71p9JIFyYHm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719673686,"user_tz":-120,"elapsed":6129,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"c7251692-4adf-45cc-b693-c581d97a673a"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few preprocessed training examples...\n","{'inputs_pretokenized': b'CONSTRUCT:public void setupHomeActivity() { super.setupHomeActivity(); if ( <extra_id_0>) { mActivity.getActionBar().setDisplayOptions( 0, ActionBar.DISPLAY_SHOW_HOME | ActionBar.DISPLAY_SHOW_TITLE); } else { mActivity.getActionBar().setDisplayOptions( ActionBar.DISPLAY_USE_LOGO, ActionBar.DISPLAY_USE_LOGO | ActionBar.DISPLAY_SHOW_TITLE); } } <CONST> ActivityHelperHoneycomb(Activity) <INV> <OTH> void onPostCreate(Bundle), boolean onCreateOptionsMenu(Menu), boolean onOptionsItemSelected(MenuItem), void setupSubActivity(), void setActionBarTitle(CharSequence), void setActionBarColor(int), void setRefreshActionButtonCompatState(boolean)', 'inputs': array([12094, 30813,    78,  2825,    65,  2193,  4462,  5733,  1927,\n","          20,   436,    12,  2060,   627,  4462,  5733, 12329,    56,\n","           4, 32099,    91,    20,   101,  5733,    12,  1323,  1001,\n","        5099,  1927,    12,  2060,  5772,  1044,   451,    88,     9,\n","        2758,  5099,    12, 15497,    35, 21626,    35, 13409,  1338,\n","        2758,  5099,    12, 15497,    35, 21626,    35, 12814,  4767,\n","          21,   203,    20,   101,  5733,    12,  1323,  1001,  5099,\n","        1927,    12,  2060,  5772,  1044,   451,  2758,  5099,    12,\n","       15497,    35, 14607,    35,  9957,   862,     9,  2758,  5099,\n","          12, 15497,    35, 14607,    35,  9957,   862,  1338,  2758,\n","        5099,    12, 15497,    35, 21626,    35, 12814,  4767,    21,\n","          21,    52, 28566,  1302, 10647,  1211,   868,   758, 16480,\n","         451,  5733,    91,    52,  3533,   744,  1302,    52, 28174,\n","        1302,    65,    44,  4278,  2560,   451,  4211,   425,   177,\n","          44,  2560,  1044,  5774,   451,  5774,   425,   177,    44,\n","        1044,   847,  6677,   451,  9453,   425,    65,  2193,  2664,\n","        5733, 15496,    65, 17886,  5099,  4047,   451, 27244,   425,\n","          65, 17886,  5099,  3566,   451,  2886,   425,    65,    94,\n","        8375,  1001,  2791, 11511,  1097,   586,   451, 14653,    91,\n","           1], dtype=int32), 'targets_pretokenized': b'UIUtils.isTablet(mActivity)', 'targets': array([6448,  821,   12,  660,  750,   46,  451,  104, 5733,   91,    1],\n","      dtype=int32)}\n","{'inputs_pretokenized': b'CONSTRUCT:public Query resolve(String fullTextQuery, boolean forceOnlyLocal) { if (fullTextQuery != null && !TextUtils.isEmpty( <extra_id_0>)) { Query q = Query.get(fullTextQuery, forceOnlyLocal); resolve(q, forceOnlyLocal); return q; } return null; } <CONST> PipeLine() <INV> Query resolve(Query, boolean), HashSet resolve(Set, boolean), Query resolve(String), Query resolve(Query), HashSet resolve(Set) <OTH> PipeLine get(), void onPluginLoaded(ScriptAccount), void addScriptAccount(ScriptAccount), void addResolver(ScriptResolver), void removeResolver(ScriptResolver), ScriptResolver getResolver(String), ArrayList getScriptResolvers(), boolean shouldResolve(Collection, Query, boolean), boolean shouldResolve(Resolver, Query, boolean), void reportResults(Query, ArrayList, String), void lookupUrl(String)', 'inputs': array([12094, 30813,    78,  2825,  1897,  2074,   451,   529,   543,\n","        1147,   683,     9,   177,  2353,  3494,  3038,    91,    20,\n","          56,     4, 11282,  1147,   683,   161,    70,   311,   302,\n","        1147,   821,    12,   660,  3579,   451, 32099,  6275,    20,\n","        1897,  2369,    24,  1897,    12,  1323,   451, 11282,  1147,\n","         683,     9,  2353,  3494,  3038,  4767,  2074,   451,  2129,\n","           9,  2353,  3494,  3038,  4767,    40,  2369,   204,    21,\n","          40,    70,   204,    21,    52, 28566,  1302, 13009,  1756,\n","        1927,    52,  3533,   744,  1302,  1897,  2074,   451,   683,\n","           9,   177,   425,  3142,  2074,   451,   628,     9,   177,\n","         425,  1897,  2074,   451,   529,   425,  1897,  2074,   451,\n","         683,   425,  3142,  2074,   451,   628,    91,    52, 28174,\n","        1302, 13009,  1756,    51, 15496,    65,    44,  3400, 10832,\n","         451,  3505,  3088,   425,    65,   118,  3505,  3088,   451,\n","        3505,  3088,   425,    65,   118,  3036,   451,  3505,  3036,\n","         425,    65,   613,  3036,   451,  3505,  3036,   425,  7999,\n","        3036,    51,  3036,   451,   529,   425,   729, 21833,  3036,\n","           8, 15496,   177,   270, 12190,   451,  1631,     9,  1897,\n","           9,   177,   425,   177,   270, 12190,   451,  3036,     9,\n","        1897,     9,   177,   425,    65,  1042,  3826,   451,   683,\n","           9,   729,     9,    53,   425,    65,  4484,  1366,   451,\n","         529,    91,     1], dtype=int32), 'targets_pretokenized': b'fullTextQuery', 'targets': array([ 543, 1147,  683,    1], dtype=int32)}\n","{'inputs_pretokenized': b'CONSTRUCT:protected Map<String, Object> getPreferences(Map<String, Object> source) { Map<String, Object> result = new HashMap<>(); PreferenceScreen preferenceScreen = getPreferenceScreen(); for (int index = 0; index < preferenceScreen.getPreferenceCount(); index++) { Preference preference = preferenceScreen.getPreference(index); result.put(preference.getKey(), getPreference( <extra_id_0>)); } return result; } <CONST> <INV> boolean operation(Operation) <OTH> View onCreateView(LayoutInflater, ViewGroup, Bundle), void onInflate(Bundle), boolean onPreferenceChange(Preference, Object), void putValue(Map, int, Object), String getString(Map, int), int getInt(Map, int), boolean getBoolean(Map, int), Uri getUri(Map, int), boolean hasChanges(Map, Map, String), boolean hasChanges(Map, Map, int), Map getValues(), void setPreferences(Map), void setPreference(Preference, Object), Object getPreference(Preference, Map), boolean setValues(Map, Map), boolean saveChanges()', 'inputs': array([12094, 30813,    78, 24154,   333,  4298,   529,     9,   198,\n","        1302,    51,  8123,   451,   353,  4298,   529,     9,   198,\n","        1302,   582,    91,    20,   333,  4298,   529,     9,   198,\n","        1302,   171,    24,    39,  1410,  4298,  1302, 12329,     6,\n","        8002, 10931, 10471, 10931,    24,    51,  8002, 10931, 12329,\n","          32,     4,  2886,   579,    24,    88,   204,   579,    52,\n","       10471, 10931,    12,  1323,  8002,   531, 12329,   579, 15897,\n","          91,    20,     6,  8002, 10471,    24, 10471, 10931,    12,\n","        1323,  8002,   451,  4921,  4767,   171,    12, 10361,   451,\n","         374, 11799,    12,  1323,   342, 15496,    51,  8002,   451,\n","       32099,    91,  4767,    21,    40,   171,   204,    21,    52,\n","       28566,  1302,    52,  3533,   744,  1302,   177,  1616,   451,\n","        1217,    91,    52, 28174,  1302,  3977,    44,  2560,  1351,\n","         451,  2866, 20288, 23556,     9,  3977,   564,     9,  7593,\n","         425,    65,    44, 20288,  8892,   451,  4211,   425,   177,\n","          44,  8002,  2892,   451,  8002,     9,   198,   425,    65,\n","         215,   275,   451,   353,     9,    99,     9,   198,   425,\n","          53,  1996,   451,   353,     9,    99,   425,    99,  5713,\n","         451,   353,     9,    99,   425,   177,  8531,   451,   353,\n","           9,    99,   425, 16566, 13086,   451,   353,     9,    99,\n","         425,   177,    87,  7410,   451,   353,     9,   333,     9,\n","          53,   425,   177,    87,  7410,   451,   353,     9,   333,\n","           9,    99,   425,   333, 14079, 15496,    65,    94,  8123,\n","         451,   353,   425,    65,    94,  8002,   451,  8002,     9,\n","         198,   425,   198,    51,  8002,   451,  8002,     9,   333,\n","         425,   177,  3242,     8,   451,   353,     9,   333,   425,\n","         177,   869,  7410,  1927,     1], dtype=int32), 'targets_pretokenized': b'preference, source', 'targets': array([10471,     9,   582,     1], dtype=int32)}\n","{'inputs_pretokenized': b'CONSTRUCT:public String getChartTitle() { if (this.getArguments() != null && this.getArguments().getString( <extra_id_0>) != null) { return this.getArguments().getString(FragmentParameters.CHART_TITLE); } return \"UNDEFINED_TITLE\"; } <CONST> ChartFragment() <INV> <OTH> DefaultRenderer buildCategoryRenderer(int), View onCreateView(LayoutInflater, ViewGroup, Bundle), void onSaveInstanceState(Bundle)', 'inputs': array([12094, 30813,    78,  2825,    53,    51,  9019,  4047,  1927,\n","          20,    56,     4,  5885,    12,  1323,  5961,  1927,   161,\n","          70,   311,    49,    12,  1323,  5961,  1927,    12,  1323,\n","         529,   451, 32099,    91,   161,    70,    91,    20,    40,\n","          49,    12,  1323,  5961,  1927,    12,  1323,   529,   451,\n","        6197,  1533,    12, 18372,   507,    35, 12814,  4767,    21,\n","          40,    29,  6993, 27842,    35, 12814,    26,   204,    21,\n","          52, 28566,  1302,  8558,  6197,  1927,    52,  3533,   744,\n","        1302,    52, 28174,  1302,  2076,  6398,   299,  3792,  6398,\n","         451,  2886,   425,  3977,    44,  2560,  1351,   451,  2866,\n","       20288, 23556,     9,  3977,   564,     9,  7593,   425,    65,\n","          44,  6473, 25708,   451,  4211,    91,     1], dtype=int32), 'targets_pretokenized': b'FragmentParameters.CHART_TITLE', 'targets': array([16626,  1533,    12, 18372,   507,    35, 12814,     1],\n","      dtype=int32)}\n","{'inputs_pretokenized': b'CONSTRUCT:public static String getPredatorCurrentDate() { return new SimpleDateFormat(PREDATOR_DATE_PATTERN_ORIGINAL_FORMAT, Locale.getDefault()) .format( <extra_id_0>); } <CONST> DateUtils() <INV> <OTH> long predatorDateToMillis(String), String getPredatorPostPreviousDate(String), String getPredatorPostDate(String), String getPredatorPostCompleteDate(String), long hoursToSeconds(String), long hoursToSeconds(int), int daysBetween(Calendar, Calendar)', 'inputs': array([12094, 30813,    78,  2825,   190,    53, 22652,    34,  2023,\n","        4754,  1067,  1927,    20,    40,    39,     6, 12220,   451,\n","        5564,  1854, 18157,    35,  8785,    35, 10527,    35, 22478,\n","          35,  8808,     9,  4175,    12,  1323,  2619, 23620,     7,\n","        8993,   451, 32099,  4767,    21,    52, 28566,  1302, 19772,\n","        1927,    52,  3533,   744,  1302,    52, 28174,  1302,   174,\n","       12328,  2023,  1067,   379,  6324,   451,   529,   425,    53,\n","       22652,    34,  2023,  4278,  8678,  1067,   451,   529,   425,\n","          53, 22652,    34,  2023,  4278,  1067,   451,   529,   425,\n","          53, 22652,    34,  2023,  4278,  4996,  1067,   451,   529,\n","         425,   174,  1007,   379,  6525,   451,   529,   425,   174,\n","        1007,   379,  6525,   451,  2886,   425,    99,   720,  9316,\n","         451,  7344,     9,  3541,    91,     1], dtype=int32), 'targets_pretokenized': b'Calendar.getInstance().getTime()', 'targets': array([3541,   12, 1323,  997, 1927,   12, 1323,  770, 1927,    1],\n","      dtype=int32)}\n"]}],"source":["nq_task = t5.data.TaskRegistry.get(\"construct\")\n","ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": SEQ_LENGTH, \"targets\": SEQ_LENGTH})\n","print(\"A few preprocessed training examples...\")\n","for ex in tfds.as_numpy(ds.take(5)):\n","  print(ex)\n"]},{"cell_type":"markdown","metadata":{"id":"yB-KY403kcCn"},"source":["JAVA TOKEN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"UNi7HPiOz27q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719675142,"user_tz":-120,"elapsed":1461,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"ec9aa0dc-b0c8-4e71-d45e-11bf4473e05f"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few raw valid examples...\n","{'input': b'public static Analyzer fromSpec(final JSONObject json, final String analyzerKey) throws JSONException { JSONObject spec = json.optJSONObject(analyzerKey<extra_id_0> if (spec != null) { return getAnalyzer(spec); } else { return getAnalyzer(json.optString(analyzerKey, Constants.DEFAULT_ANALYZER)); } }', 'output': b');'}\n","{'input': b'public static Analyzer getAnalyzer(final String str) throws JSONException { final String[] parts = str.split(\":\", 2); final String name = parts[0].toUpperCase(); final String args = parts.length == 2 <extra_id_0> return Analyzers.valueOf(name).newAnalyzer(args); }', 'output': b'? parts[1] : null;'}\n","{'input': b'private static List<ParamSpec> getParamSpecs(JSONArray jsonParams) throws ParameterException, JSONException { final List<ParamSpec> paramSpecs = new ArrayList<>(); if (jsonParams != null) { for (int i = 0; i < jsonParams.length()<extra_id_0> paramSpecs.add(getParamSpec(jsonParams.getJSONObject(i))); } } return paramSpecs; }', 'output': b'; i++) {'}\n","{'input': b'public Analyzer newAnalyzer(final JSONObject json) throws JSONException { final Analyzer defaultAnalyzer = fromSpec(json, Constants.DEFAULT_FIELD); final Map<String, Analyzer> analyzers = new HashMap<>(); final Iterator<?> it = json.keys(); while (it.hasNext()) { final String key = it.next().toString(); <extra_id_0> continue; analyzers.put(key, fromSpec(json, key)); } return new PerFieldAnalyzerWrapper(defaultAnalyzer, analyzers); }', 'output': b'if (Constants.DEFAULT_FIELD.equals(key))'}\n","{'input': b'public Analyzer newAnalyzer(final JSONObject json) throws JSONException { Analyzer analyzer = fromSpec(json); int min = json.optInt(\"min\", NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE<extra_id_0> int max = json.optInt(\"max\", NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE); return new NGramAnalyzer(analyzer, min, max); }', 'output': b');'}\n"]}],"source":["def nq_token(split, shuffle_files=False):\n","  # We only have one file for each split.\n","  del shuffle_files\n","\n","  # Load lines from the text file as examples.\n","  ds = tf.data.TextLineDataset(nq_tsv_path_token[split])\n","  ds = ds.map(\n","      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n","                        field_delim=\"\\t\", use_quote_delim=False),\n","      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","  \n","  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n","  return ds\n","\n","print(\"A few raw valid examples...\")\n","for ex in tfds.as_numpy(nq_token(\"validation\").take(5)):\n","  print(ex)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VvDAbgNY0B4Y","executionInfo":{"status":"ok","timestamp":1652719675143,"user_tz":-120,"elapsed":7,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["def token_preprocessing(ds):\n","  \n","  def to_inputs_and_targets(ex):\n","\n","        inputs = tf.strings.join(['TOKEN:' + ex['input']], separator=' ')\n","        class_label = tf.strings.join([ex['output']], separator=' ')\n","        return {'inputs': inputs, 'targets': class_label }\n","    \n","  return ds.map(to_inputs_and_targets, \n","                num_parallel_calls=tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-Mm6AQfw0INC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719675143,"user_tz":-120,"elapsed":5,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"b7ddb095-6391-4f5d-b2a2-6642928c3a18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<t5.data.dataset_providers.FunctionTask at 0x7fb95793d8d0>"]},"metadata":{},"execution_count":14}],"source":["t5.data.TaskRegistry.remove('token')\n","t5.data.TaskRegistry.add(\n","    \"token\",\n","    dataset_fn=nq_token,\n","    splits=[\"train\", \"validation\"],\n","    text_preprocessor=[token_preprocessing],\n","    output_features = DEFAULT_OUTPUT_FEATURES,\n","    metric_fns=[t5.evaluation.metrics.accuracy],\n","    num_input_examples=num_nq_examples_token\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qnf25qt10Wkl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719677472,"user_tz":-120,"elapsed":2333,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"66a02828-1c4b-4e5b-cf25-7097e9b797ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few preprocessed training examples...\n","{'inputs_pretokenized': b'TOKEN:public void setPosicaoTexto(String ver, <extra_id_0> posVer = ver; posHor = hor; atualizaDataTexto(); } <CONST> BotaoBase(PApplet, PVector, float, int) <INV> void atualizaDataTexto() <OTH> void setImageBotao(String), void setPosBotaoMenor(PVector), void setDiamMen(float), void setOffsetToPosII(PVector), void setPosicaoDefault(boolean), boolean getPosDefault(), void setTamanhoTexto(float), void setColorOff(int), void setColorON(int), void setColorFixo(int), void setBotaoComoToggle(), void desenhaTexto(), void desenhaTextoYOffset(float), void desenhaTextoGira(float), void setNomeBotao(String), void setEtiqueta(String), void setNovaPos(PVector), void desenharBotaoCircular(), void desenharBotaoCircular(boolean), void desenharBotaoCircularMovil(), void desenharBotaoCircularMovil(boolean), void desenharBotaoCircularTextoGira(float), void setTamanhoEtiqueta(float), void desenharBotaoCircularSemTexto(), boolean botaoToogleOnClick(PVector), boolean botaoOnClick(PVector), boolean botaoOnClickPos(PVector), void turnBotaoOn(), void turnBotaoOff(), boolean botaoOnClick(PVector, float, PVector), boolean getEstadoBotao(), void setEstadoBotao(boolean), void atualizaCor(), int getColorOn(), void testMudanca(boolean), PVector getPosicao(), void desenhaLogoSound(), void desenhaLogoSound(int), void desenhaFlecha(), void desenhaFlechaMovil(), float getBotaoDiam()', 'inputs': array([18964,    78,  2825,    65,    94,  4277,  5169,   233,  1147,\n","         233,   451,   529,  9512,     9, 32099,  1679,  9222,    24,\n","        9512,   204,  1679, 22573,    24,  2464,   204,    68,  1102,\n","       19238,   337,  1147,   233, 12329,    21,    52, 28566,  1302,\n","         164,  3430,   233,  1869,   451,   602, 15026,    46,     9,\n","         175,  4662,     9,  2383,     9,    99,    91,    52,  3533,\n","         744,  1302,    65,    68,  1102, 19238,   337,  1147,   233,\n","        1927,    52, 28174,  1302,    65, 26033,   422,  3430,   233,\n","         451,   529,   425,    65,    94,  4277,   422,  3430,   233,\n","       18967,   280,   451,   602,  4662,   425,    65, 20149,  3113,\n","       18967,   451, 12447,   425,    65,    94,  2336,   379,  4277,\n","        4852,   451,   602,  4662,   425,    65,    94,  4277,  5169,\n","         233,  2619,   451, 14653,   425,   177,    51,  4277,  2619,\n","       15496,    65,    94, 16364,   481,  4468,  1147,   233,   451,\n","       12447,   425,    65, 19200,  7877,   451,  2886,   425,    65,\n","       19200,  4669,   451,  2886,   425,    65, 19200, 16066,   233,\n","         451,  2886,   425,    65,    94,   422,  3430,   233, 10540,\n","         233, 18143, 15496,    65,  9879, 19766,  1147,   233, 15496,\n","          65,  9879, 19766,  1147,   233,   985,  2336,   451, 12447,\n","         425,    65,  9879, 19766,  1147,   233, 21522,   103,   451,\n","       12447,   425,    65,    94,  1276,  2022,   422,  3430,   233,\n","         451,   529,   425,    65, 21431,    46,  5025,  1670,   451,\n","         529,   425,    65,    94, 14196,   103,  4277,   451,   602,\n","        4662,   425,    65,   254,  6975,  6495,   422,  3430,   233,\n","       21821, 15496,    65,   254,  6975,  6495,   422,  3430,   233,\n","       21821,   451, 14653,   425,    65,   254,  6975,  6495,   422,\n","        3430,   233, 21821,  9954,  1636, 15496,    65,   254,  6975,\n","        6495,   422,  3430,   233, 21821,  9954,  1636,   451, 14653,\n","         425,    65,   254,  6975,  6495,   422,  3430,   233, 21821,\n","        1147,   233, 21522,   103,   451, 12447,   425,    65,    94,\n","       16364,   481,  4468,   676,    46,  5025,  1670,   451, 12447,\n","         425,    65,   254,  6975,  6495,   422,  3430,   233, 21821,\n","         176,  2653,  1147,   233, 15496,   177,    45,  3430,   233,\n","       15594, 11868,   862,  5629,   451,   602,  4662,   425,   177,\n","          45,  3430,   233,   862,  5629,   451,   602,  4662,   425,\n","         177,    45,  3430,   233,   862,  5629,  4277,   451,   602,\n","        4662,   425,    65,   922,   422,  3430,   233,  1033, 15496,\n","          65,   922,   422,  3430,   233,  7877, 15496,   177,    45,\n","        3430,   233,   862,  5629,   451,   602,  4662,     9,  2383,\n","           9,   175,  4662,   425,   177, 10310,   470,  3173,   422,\n","        3430,   233, 15496,    65, 21431,   470,  3173,   422,  3430,\n","         233,   451, 14653,   425,    65,    68,  1102, 19238, 18000,\n","       15496,    99, 16345,  1033, 15496,    65,   169,   639,  9757,\n","       19232,   451, 14653,   425,   175,  4662,    51,  4277,  5169,\n","         233, 15496,    65,  9879, 19766, 23800,  5947, 15496,    65,\n","        9879, 19766, 23800,  5947,   451,  2886,   425,    65,  9879,\n","       19766,   748,   380,  2824, 15496,    65,  9879, 19766,   748,\n","         380,  2824,  9954,  1636, 15496,  2383, 15367,  3430,   233,\n","         347,  3113,  1927,     1], dtype=int32), 'targets_pretokenized': b'String hor){', 'targets': array([  53, 2464,   91, 4828,    1], dtype=int32)}\n","{'inputs_pretokenized': b'TOKEN:public void genToken() { try { if ( MainActivity.GENERATING_TOKEN ) { LL_PROGRESS.setVisibility(View.VISIBLE); BT_GENERATE.setEnabled(false); } else { LL_PROGRESS.setVisibility(View.GONE <extra_id_0> BT_GENERATE.setEnabled(true); } } catch (Exception e) {} } <CONST> <INV> <OTH> void onCreate(Bundle), View onCreateView(LayoutInflater, ViewGroup, Bundle), void updateProgress(int, String), void clearDomain()', 'inputs': array([18964,    78,  2825,    65,  2788,  1169,  1927,    20,   226,\n","          20,    56,     4,  4883,  5733,    12, 28672,   806, 22197,\n","          35,  8295,     5,    20,     6, 12257,    35, 26160,    12,\n","        2060, 11029,   451,  1351,    12, 30074,  4767, 20249,    35,\n","       28672, 18739,    12,  2060,  1981,   451,  5346,  4767,    21,\n","         203,    20,     6, 12257,    35, 26160,    12,  2060, 11029,\n","         451,  1351,    12,   875,  8937, 32099, 20249,    35, 28672,\n","       18739,    12,  2060,  1981,   451,  3246,  4767,    21,    21,\n","         328,     4,   117,    77,    91, 12812,    21,    52, 28566,\n","        1302,    52,  3533,   744,  1302,    52, 28174,  1302,    65,\n","          44,  2560,   451,  4211,   425,  3977,    44,  2560,  1351,\n","         451,  2866, 20288, 23556,     9,  3977,   564,     9,  7593,\n","         425,    65,   611,  8357,   451,  2886,     9,    53,   425,\n","          65,   689,  3696,  1927,     1], dtype=int32), 'targets_pretokenized': b');', 'targets': array([  5, 204,   1], dtype=int32)}\n","{'inputs_pretokenized': b'TOKEN:private void printObject(Destination object, final ViewHolder holder) { holder.txtNome.setText(object.getNome()); holder.txtRegiao.setText(object.getRegiao()); holder.txtPais <extra_id_0> Picasso.with(context).load(object.getImage_url()) .fit() .centerCrop() .placeholder(R.drawable.holder) .into(holder.imageView); } <CONST> ListAdapter(Activity, List) <INV> View getView(int, View, ViewGroup) <OTH> int getCount(), Destination getItem(int), long getItemId(int), ViewHolder getViewHolder(View)', 'inputs': array([18964,    78, 14566,    65,   948,   587,   451,  7941,   921,\n","           9,    85,  3977,  2984,  6221,    91,    20,  6221,    12,\n","        5290,  1276,  2022,    12,  2060,  1147,   451,  7427,    12,\n","        1323,  1276,  2022, 27706,  6221,    12,  5290, 12105,   484,\n","         233,    12,  2060,  1147,   451,  7427,    12,  1323, 12105,\n","         484,   233, 27706,  6221,    12,  5290, 10206,   660, 32099,\n","       11793, 19615,    12,  3439,   451,  8556,   437,  8818,   451,\n","        7427,    12,  1323,  2256,    35,  5418, 23620,     7,  4319,\n","        1927,     7,  9760, 27295,  1927,     7,  2954, 10726,   451,\n","         806,    12, 14470,   202,    12, 10726,    91,     7, 22645,\n","         451, 10726,    12,  7767,  1351,  4767,    21,    52, 28566,\n","        1302,   163,  2690,   451,  5733,     9,   163,    91,    52,\n","        3533,   744,  1302,  3977, 12478,   451,  2886,     9,  3977,\n","           9,  3977,   564,    91,    52, 28174,  1302,    99,  9376,\n","       15496, 15550,  9031,   451,  2886,   425,   174,    51, 15435,\n","         451,  2886,   425,  3977,  2984, 12478,  2984,   451,  1351,\n","          91,     1], dtype=int32), 'targets_pretokenized': b'.setText(object.getPais());', 'targets': array([    7,  2060,  1147,   451,  7427,    12,  1323, 10206,   660,\n","       27706,     1], dtype=int32)}\n","{'inputs_pretokenized': b'TOKEN:public static int getScreenWidth(Context context) { int screenWidth; WindowManager wm = (WindowManager) context.getSystemService(Context.WINDOW_SERVICE); Display display = wm.getDefaultDisplay(); final Point point = new Point(); try <extra_id_0> display.getSize(point); } catch (java.lang.NoSuchMethodError ignore) { point.x = display.getWidth(); point.y = display.getHeight(); } screenWidth = point.x; return screenWidth; } <CONST> <INV> <OTH> void showtoastLngthshort(Context, String), void showtoastLngthlong(Context, String), void cancelToast(), void logManager(int, String), boolean isNetConnected(Context), void hideSoftKeyboard(Activity), ArrayList strCommaToArray(String), String getcurrentDateFirstTimestamp(), String getcurrentDateLastTimestamp(), String getcurrentTimestamp(), String getcurrentDate(), String getAftrCreditperiodTimestamp(int), String getDateFromTimestamp(long), long getTimestampFromDate(String), String getPrvsdateGromGivendate(String), String get_nextdate_from_givendate(String), String changeDateFormate(String, String, String), void showUsrNtfy(Context, LinearLayout, TextView, int, int, String), void showUsrNtfyAutoHide(Context, LinearLayout, TextView, int, int, String, int), void hideUsrNtfy(Context, LinearLayout), void showImgsDwnldNtfy(Context, LinearLayout), void hideImgsDwnldNtfy(Context, LinearLayout), void updateTextofImgsDwnldNtfy(Context, int, LinearLayout, TextView, TextView, int), boolean isvalidEmailaddrsFrmt(CharSequence), String get2DecimalDigitOfDouble(double), String get2DigitDecimal(String, boolean), boolean checkGpsEnbldsblWithRetrnStatus(Context), boolean isServiceRunning(Class, Context), String encodeTobase64(Bitmap), ArrayList getPrimaryColorArray(Context), ArrayList getFilePaths(File, ArrayList), boolean IsSupportedFile(String), void saveBitmapToDevice(Bitmap, String, String), void renameFilenameInDevice(String, String, String)', 'inputs': array([18964,    78,  2825,   190,    99,    51, 10931,  4238,   451,\n","         282,   330,    91,    20,    99,  1674,  4238,   204,  6069,\n","         485,   166,   104,    24,     4,  3437,   485,    91,   330,\n","          12,  1323,  2927,   294,   451,   282,    12, 16338,    35,\n","        8359,  4767, 10120,  1582,    24,   166,   104,    12,  1323,\n","        2619,  5772, 12329,    85,  3666,   857,    24,    39,  3666,\n","       12329,   226, 32099,  1582,    12,  1323,   759,   451,  3791,\n","        4767,    21,   328,     4,  3976,    12,  4140,    12,  1276,\n","       11999,  1080,  1168,  5075,    91,    20,   857,    12,    15,\n","          24,  1582,    12,  1323,  4238, 12329,   857,    12,    61,\n","          24,  1582,    12,  1323,  4495, 12329,    21,  1674,  4238,\n","          24,   857,    12,    15,   204,    40,  1674,  4238,   204,\n","          21,    52, 28566,  1302,    52,  3533,   744,  1302,    52,\n","       28174,  1302,    65,   276,    46,  2796,   370,   515,   147,\n","       12176,   451,   282,     9,    53,   425,    65,   276,    46,\n","        2796,   370,   515,   147,   598,   451,   282,     9,    53,\n","         425,    65,  4931,   379,  2077, 15496,    65,  1048,   485,\n","         451,  2886,     9,    53,   425,   177,    28,  6790, 11325,\n","         451,   282,   425,    65,  6383, 11869,   342,  2243,   451,\n","        5733,   425,   729,  1047, 19763,   379,  1199,   451,   529,\n","         425,    53,    51,  7060,  1067,  2629,  3308, 15496,    53,\n","          51,  7060,  1067,  2844,  3308, 15496,    53,    51,  7060,\n","        3308, 15496,    53,    51,  7060,  1067, 15496,    53, 11099,\n","        2140,   180, 14015, 21357,  3308,   451,  2886,   425,    53,\n","        9580,   784,  3308,   451,   598,   425,   174, 10333,   784,\n","        1067,   451,   529,   425,    53,  9540, 13978,     8,  2701,\n","         875, 15775, 13300,  2701,   451,   529,   425,    53,    51,\n","          35, 12800,  2701,    35,  5036,    35, 18741,  2701,   451,\n","         529,   425,    53,   694, 15374,    63,   451,   529,     9,\n","          53,     9,    53,   425,    65,   276,  1655,     8,   180,\n","         824,    46, 12650,   451,   282,     9, 23288,  2866,     9,\n","        3693,  1351,     9,    99,     9,    99,     9,    53,   425,\n","          65,   276,  1655,     8,   180,   824,    46, 12650,  5680,\n","       15801,   451,   282,     9, 23288,  2866,     9,  3693,  1351,\n","           9,    99,     9,    99,     9,    53,     9,    99,   425,\n","          65,  6383,  1655,     8,   180,   824,    46, 12650,   451,\n","         282,     9, 23288,  2866,   425,    65,   276, 24863,     8,\n","         347,  1439,  1172,   824,    46, 12650,   451,   282,     9,\n","       23288,  2866,   425,    65,  6383, 24863,     8,   347,  1439,\n","        1172,   824,    46, 12650,   451,   282,     9, 23288,  2866,\n","         425,    65,   611,  1147,  1441, 24863,     8,   347,  1439,\n","        1172,   824,    46, 12650,   451,   282,     9,    99,     9,\n","       23288,  2866,     9,  3693,  1351,     9,  3693,  1351,     9,\n","          99,   425,   177,    28, 16440,  5463, 25090,     8,   748,\n","        2498,    46,   451, 27244,   425,    53,    51,    96,  9745,\n","       14731,  1086,  3293,   451, 10460,   425,    53,    51,    96,\n","       14731,  9745,   451,   529,     9,   177,   425,   177,   383,\n","         875,  2645, 12261,   155,  1172,     8,  8908,   449, 22132,\n","         180,    25,   734,   451,   282,   425,   177,    28,   294,\n","        7630,   451,   553,     9,  3249,   425,    53,  3622,   379,\n","        4386,  2366,   451, 17469,   425,   729, 20308,  3566,  1199,\n","         451,   282,   425,   729,    51,  8509,     8,   451,   445,\n","           9,   729,   425,   177,    48,     8,  8125,   445,   451,\n","         529,   425,    65,   869, 17469,   379,  3790,   451, 17469,\n","           9,    53,     9,    53,   425,    65, 11423, 11040,   539,\n","        3790,   451,   529,     9,    53,     9,    53,    91,     1],\n","      dtype=int32), 'targets_pretokenized': b'{', 'targets': array([20,  1], dtype=int32)}\n","{'inputs_pretokenized': b'TOKEN:public String getType(@NonNull final Uri uri) { final int matchCode = URI_MATCHER.match(uri); if (RETURN_TYPES <extra_id_0> return RETURN_TYPES.get(matchCode); } return super.getType(uri); } <CONST> GeomemorialDbProvider() <INV> <OTH> boolean onCreate(), Cursor query(Uri, String, String, String, String)', 'inputs': array([18964,    78,  2825,    53,  1354, 23610, 18588,    85, 16566,\n","        2106,    91,    20,    85,    99,  1136,  1259,    24,  2462,\n","          35, 12603,  3698,    12,  8938,   451,  4621,  4767,    56,\n","           4, 23784,    35, 14955, 32099,    40, 19439,    35, 14955,\n","          12,  1323,   451,  8938,  1259,  4767,    21,    40,   436,\n","          12,  1323,   142,   451,  4621,  4767,    21,    52, 28566,\n","        1302,  7437, 12540,  1016,  5544,   749,  1927,    52,  3533,\n","         744,  1302,    52, 28174,  1302,   177,    44,  2560, 15496,\n","       19744,   573,   451,  2080,     9,    53,     9,    53,     9,\n","          53,     9,    53,    91,     1], dtype=int32), 'targets_pretokenized': b'.indexOfKey(matchCode) >= 0){', 'targets': array([   7, 4921, 1086,  342,  451, 8938, 1259,   91, 2224,   88,   91,\n","       4828,    1], dtype=int32)}\n"]}],"source":["nq_task = t5.data.TaskRegistry.get(\"token\")\n","ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": SEQ_LENGTH, \"targets\": SEQ_LENGTH})\n","print(\"A few preprocessed training examples...\")\n","for ex in tfds.as_numpy(ds.take(5)):\n","  print(ex)\n"]},{"cell_type":"markdown","metadata":{"id":"ZIe-u5l9ke6x"},"source":["JAVA BLOCK"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"yr0TT18ejMtY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719678126,"user_tz":-120,"elapsed":660,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"f20d5966-ed6b-4692-ea55-6da940752a4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few raw valid examples...\n","{'input': b'public void removeItem(int position, boolean argIsSilent) { if (position < 0) <extra_id_0> int size = mInternalPlaylist.size(); if (size > position) { mInternalPlaylist.remove(position); } if (!argIsSilent) notifyPlaylistChanged(); } <CONST> Playlist(Context, int), Playlist(Context, int, boolean), Playlist(Context) <INV> int size(), void notifyPlaylistChanged(), void removeItem(int) <OTH> void setContext(Context), void destroy(), ArrayList getPlaylist(), int defaultSize(), IEpisode getItem(int), IEpisode getNext(), int getPosition(IEpisode), void setAsFrist(IEpisode), void setItem(int, IEpisode), boolean maybeInsert(IEpisode), boolean insertEpisodeInternal(IEpisode), void removeFirst(), IEpisode nextEpisode(), void move(int, int), void queue(IEpisode), List getMediaItems(PlayerService), String getOrder(), String getWhere(), void resetPlaylist(CursorAdapter), boolean populatePlaylistIfEmpty(), void populatePlaylist(), void populatePlaylist(int, boolean), void persist(Context, FeedItem, FeedItem, int, int), boolean contains(IEpisode), boolean isEmpty(), IEpisode first(), void notifyDatabaseChanged(), void onPlaylistChanged(PlaylistData), void showOnlyDownloaded(boolean), void setSortOrder(int), void setShowListened(boolean), SubscriptionFilter getSubscriptionFilter(), void setIsLoaded(boolean), boolean isLoaded(), Single getLoadedPlaylist(), void notifyFiltersChanged(), void onSharedPreferenceChanged(SharedPreferences, String), void refresh(Context), void changePlaylistFilter(Context, Playlist, int), int comparePlaylistOrder(IEpisode, IEpisode)', 'output': b'{ VendorCrashReporter.report(\"Playlist remove\", \"Position must be greater or equal to zero\"); return; }'}\n","{'input': b'public void removeItem(int position, boolean argIsSilent) { if (position < 0) { VendorCrashReporter.report(\"Playlist remove\", \"Position must be greater or equal to zero\"); return; } int size = mInternalPlaylist.size(); if (size > position) <extra_id_0> if (!argIsSilent) notifyPlaylistChanged(); } <CONST> Playlist(Context, int), Playlist(Context, int, boolean), Playlist(Context) <INV> int size(), void notifyPlaylistChanged(), void removeItem(int) <OTH> void setContext(Context), void destroy(), ArrayList getPlaylist(), int defaultSize(), IEpisode getItem(int), IEpisode getNext(), int getPosition(IEpisode), void setAsFrist(IEpisode), void setItem(int, IEpisode), boolean maybeInsert(IEpisode), boolean insertEpisodeInternal(IEpisode), void removeFirst(), IEpisode nextEpisode(), void move(int, int), void queue(IEpisode), List getMediaItems(PlayerService), String getOrder(), String getWhere(), void resetPlaylist(CursorAdapter), boolean populatePlaylistIfEmpty(), void populatePlaylist(), void populatePlaylist(int, boolean), void persist(Context, FeedItem, FeedItem, int, int), boolean contains(IEpisode), boolean isEmpty(), IEpisode first(), void notifyDatabaseChanged(), void onPlaylistChanged(PlaylistData), void showOnlyDownloaded(boolean), void setSortOrder(int), void setShowListened(boolean), SubscriptionFilter getSubscriptionFilter(), void setIsLoaded(boolean), boolean isLoaded(), Single getLoadedPlaylist(), void notifyFiltersChanged(), void onSharedPreferenceChanged(SharedPreferences, String), void refresh(Context), void changePlaylistFilter(Context, Playlist, int), int comparePlaylistOrder(IEpisode, IEpisode)', 'output': b'{ mInternalPlaylist.remove(position); }'}\n","{'input': b'public void removeItem(int position, boolean argIsSilent) { if (position < 0) { VendorCrashReporter.report(\"Playlist remove\", \"Position must be greater or equal to zero\"); return; } int size = mInternalPlaylist.size(); if (size > position) { mInternalPlaylist.remove(position); } if (!argIsSilent) <extra_id_0> } <CONST> Playlist(Context, int), Playlist(Context, int, boolean), Playlist(Context) <INV> int size(), void removeItem(int) <OTH> void setContext(Context), void destroy(), ArrayList getPlaylist(), int defaultSize(), IEpisode getItem(int), IEpisode getNext(), int getPosition(IEpisode), void setAsFrist(IEpisode), void setItem(int, IEpisode), boolean maybeInsert(IEpisode), boolean insertEpisodeInternal(IEpisode), void removeFirst(), IEpisode nextEpisode(), void move(int, int), void queue(IEpisode), List getMediaItems(PlayerService), String getOrder(), String getWhere(), void resetPlaylist(CursorAdapter), boolean populatePlaylistIfEmpty(), void populatePlaylist(), void populatePlaylist(int, boolean), void persist(Context, FeedItem, FeedItem, int, int), boolean contains(IEpisode), boolean isEmpty(), IEpisode first(), void notifyDatabaseChanged(), void notifyPlaylistChanged(), void onPlaylistChanged(PlaylistData), void showOnlyDownloaded(boolean), void setSortOrder(int), void setShowListened(boolean), SubscriptionFilter getSubscriptionFilter(), void setIsLoaded(boolean), boolean isLoaded(), Single getLoadedPlaylist(), void notifyFiltersChanged(), void onSharedPreferenceChanged(SharedPreferences, String), void refresh(Context), void changePlaylistFilter(Context, Playlist, int), int comparePlaylistOrder(IEpisode, IEpisode)', 'output': b'notifyPlaylistChanged();'}\n","{'input': b'public static void onMainActivityHidden(int depth) { currentBridge = genericBridge; if (guiListener != null) <extra_id_0> AndroidSingleton.activity = null; } <CONST> AndroidSingleton() <INV> <OTH> void onCreateMainActivity(MainActivity, GuiInterfaceBridge, List), void onMainActivityVisible(int), void onRealDestroy(), void onEarlyShareIntent(List), void serviceStopping(), void serviceReady(AndroidGuiListener, int), GuiInterfaceBridge getInterfaceBridge(), void sendQuickShare()', 'output': b'{ guiListener.guiHidden(depth); }'}\n","{'input': b'public void autoCorrectCapitalization() { String enteredText = getText().toString(); if (enteredText != null && !choices.contains(enteredText) && choicesAllLowerCase.contains(enteredText.toLowerCase())) <extra_id_0> } <CONST> Combobox(Context, Vector, ComboboxAdapter) <INV> void setListeners() <OTH> void setupChoices(Vector), TextWatcher getWhileTypingValidator()', 'output': b'{ int index = choicesAllLowerCase.indexOf(enteredText.toLowerCase()); setText(choices.get(index)); }'}\n"]}],"source":["def nq_block(split, shuffle_files=False):\n","  # We only have one file for each split.\n","  del shuffle_files\n","\n","  # Load lines from the text file as examples.\n","  ds = tf.data.TextLineDataset(nq_tsv_path_block[split])\n","  ds = ds.map(\n","      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n","                        field_delim=\"\\t\", use_quote_delim=False),\n","      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","  \n","  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n","  return ds\n","\n","print(\"A few raw valid examples...\")\n","for ex in tfds.as_numpy(nq_block(\"validation\").take(5)):\n","  print(ex)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Hq0uLYNTjM9z","executionInfo":{"status":"ok","timestamp":1652719678127,"user_tz":-120,"elapsed":14,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["def block_preprocessing(ds):\n","  \n","  def to_inputs_and_targets(ex):\n","\n","        inputs = tf.strings.join(['BLOCK:' + ex['input']], separator=' ')\n","        class_label = tf.strings.join([ex['output']], separator=' ')\n","        return {'inputs': inputs, 'targets': class_label }\n","    \n","  return ds.map(to_inputs_and_targets, \n","                num_parallel_calls=tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ji4u8yhqjNER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719678127,"user_tz":-120,"elapsed":12,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"615b7cc3-9412-4697-eefb-ab89574347a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<t5.data.dataset_providers.FunctionTask at 0x7fb941ba3c10>"]},"metadata":{},"execution_count":18}],"source":["t5.data.TaskRegistry.remove('block')\n","t5.data.TaskRegistry.add(\n","    \"block\",\n","    dataset_fn=nq_block,\n","    splits=[\"train\", \"validation\"],\n","    text_preprocessor=[block_preprocessing],\n","    output_features = DEFAULT_OUTPUT_FEATURES,\n","    metric_fns=[t5.evaluation.metrics.accuracy],\n","    num_input_examples=num_nq_examples_block\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"JG09lDZdjNKr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719681055,"user_tz":-120,"elapsed":2931,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"d0c03920-d858-47ce-d115-72ab4e94fb7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["A few preprocessed training examples...\n","{'inputs_pretokenized': b'BLOCK:public void onResume() { updateSize(false); if (mCursorBlink != 0) { mHandler.postDelayed(mBlinkCursor, CURSOR_BLINK_PERIOD); } if (mKeyListener != null) <extra_id_0> } <CONST> EmulatorView(Context, TermSession, DisplayMetrics), EmulatorView(Context, AttributeSet), EmulatorView(Context, AttributeSet, int) <INV> void updateSize(boolean) <OTH> int createLinks(int), void commonConstructor(Context), void attachSession(TermSession), void setDensity(DisplayMetrics), void onPause(), void setColorScheme(ColorScheme), boolean onCheckIsTextEditor(), InputConnection onCreateInputConnection(EditorInfo), void setImeBuffer(String), boolean getKeypadApplicationMode(), void setExtGestureListener(GestureDetector), int computeVerticalScrollRange(), int computeVerticalScrollExtent(), int computeVerticalScrollOffset(), void initialize(), TermSession getTermSession(), int getVisibleWidth(), int getVisibleHeight(), int getVisibleRows(), int getVisibleColumns(), void page(int), void pageHorizontal(int), void setTextSize(int), void setUseCookedIME(boolean), boolean isMouseTrackingActive(), void sendMouseEventCode(MotionEvent, int), boolean onSingleTapUp(MotionEvent), void onLongPress(MotionEvent), boolean onScroll(MotionEvent, MotionEvent, float, float), void onSingleTapConfirmed(MotionEvent), boolean onJumpTapDown(MotionEvent, MotionEvent), boolean onJumpTapUp(MotionEvent, MotionEvent), boolean onFling(MotionEvent, MotionEvent, float, float), void onShowPress(MotionEvent), boolean onDown(MotionEvent), boolean onTouchEvent(MotionEvent), boolean onTouchEventWhileSelectingText(MotionEvent), boolean onKeyDown(int, KeyEvent), boolean isInterceptedSystemKey(int), boolean onKeyUp(int, KeyEvent), boolean onKeyPreIme(int, KeyEvent), boolean handleControlKey(int, boolean), boolean handleHardwareControlKey(int, KeyEvent), boolean handleFnKey(int, boolean), boolean isSystemKey(int, KeyEvent), void clearSpecialKeyStatus(), void updateText(), void onSizeChanged(int, int, int, int), void updateSize(int, int), void onDraw(Canvas), void ensureCursorVisible(), void toggleSelectingText(), boolean getSelectingText(), String getSelectedText(), void sendControlKey(), void sendFnKey(), void setBackKeyCharacter(int), void setAltSendsEsc(boolean), void setControlKeyCode(int), void setFnKeyCode(int), void setTermType(String), void setMouseTracking(boolean), String getURLat(float, float)', 'inputs': array([17090,    78,  2825,    65,    44, 17628,  1927,    20,   611,\n","         759,   451,  5346,  4767,    56,     4,   104,  5635,   422,\n","        5251,   161,    88,    91,    20,   101,   792,    12,  6254,\n","       19736,   451,   104,   422,  5251,  5635,     9,     6, 30627,\n","          35,   422, 16290,    35, 16230,  4767,    21,    56,     4,\n","         104,   342,  1128,   161,    70,    91, 32099,    21,    52,\n","       28566,  1302,     6, 30322,  1351,   451,   282,     9, 10247,\n","        1286,     9, 10120,  3436,   425,     6, 30322,  1351,   451,\n","         282,     9,  3518,   628,   425,     6, 30322,  1351,   451,\n","         282,     9,  3518,   628,     9,    99,    91,    52,  3533,\n","         744,  1302,    65,   611,   759,   451, 14653,    91,    52,\n","       28174,  1302,    99,   149,  9435,   451,  2886,   425,    65,\n","        1246,  7019,   451,   282,   425,    65,  7439,  1286,   451,\n","        4363,  1286,   425,    65,    94, 28540,   451,  5772,  3436,\n","         425,    65,    44, 17651, 15496,    65, 19200,  7108,   451,\n","        3566,  7108,   425,   177,    44,  2722,  1925,  1147,  3559,\n","       15496,  9333,  1161,    44,  2560,  1635,  1161,   451,  3559,\n","         391,   425,    65,    94,   392,  2022,  1594,   451,   529,\n","         425,   177,  1457,  9344,  2585,  1222, 15496,    65,    94,\n","        7865, 13903,     8,   760,  1128,   451, 13903,     8,   760,\n","       12853,   425,    99,  4624, 16653, 10795,  1907, 15496,    99,\n","        4624, 16653, 10795, 15964, 15496,    99,  4624, 16653, 10795,\n","        2336, 15496,    65,  4135, 15496, 10247,  1286, 26471,  1286,\n","       15496,    99,    51,  7570,  4238, 15496,    99,    51,  7570,\n","        4495, 15496,    99,    51,  7570,  5196, 15496,    99,    51,\n","        7570,  3429, 15496,    65,   489,   451,  2886,   425,    65,\n","         489, 16096,   451,  2886,   425,    65,  5924,   759,   451,\n","        2886,   425,    65, 15267,   323, 23385, 19513,   451, 14653,\n","         425,   177,    28, 12646, 12854,  4896, 15496,    65,   974,\n","       12646,   521,  1259,   451, 13766,   521,     9,    99,   425,\n","         177,    44,  3849, 15601,  4483,   451, 13766,   521,   425,\n","          65,    44,  2643,  4179,   451, 13766,   521,   425,   177,\n","          44, 10795,   451, 13766,   521,     9,     6, 13766,   521,\n","           9,  2383,     9,  2383,   425,    65,    44,  3849, 15601,\n","       23305,   451, 13766,   521,   425,   177,    44, 15816, 15601,\n","        7030,   451, 13766,   521,     9,     6, 13766,   521,   425,\n","         177,    44, 15816, 15601,  4483,   451, 13766,   521,     9,\n","           6, 13766,   521,   425,   177,    44,   748,   782,   451,\n","       13766,   521,     9,     6, 13766,   521,     9,  2383,     9,\n","        2383,   425,    65,    44,  7598,  4179,   451, 13766,   521,\n","         425,   177,    44,  7030,   451, 13766,   521,   425,   177,\n","          44, 17599,   521,   451, 13766,   521,   425,   177,    44,\n","       17599,   521,  3007,  3917,    27,  1147,   451, 13766,   521,\n","         425,   177,    44,   342,  7030,   451,  2886,     9, 23469,\n","         425,   177,    28, 18543,    47,  2927,   342,   451,  2886,\n","         425,   177,    44,   342,  4483,   451,  2886,     9, 23469,\n","         425,   177,    44,   342,  4886,   392,  2022,   451,  2886,\n","           9, 23469,   425,   177,  1332,  3528,   342,   451,  2886,\n","           9,   177,   425,   177,  1332, 22287,  3528,   342,   451,\n","        2886,     9, 23469,   425,   177,  1332,  8371,   342,   451,\n","        2886,     9,   177,   425,   177,    28,  2927,   342,   451,\n","        2886,     9, 23469,   425,    65,   689,  8910,   342,   734,\n","       15496,    65,   611,  1147, 15496,    65,    44,   759,  4594,\n","         451,  2886,     9,    99,     9,    99,     9,    99,   425,\n","          65,   611,   759,   451,  2886,     9,    99,   425,    65,\n","          44, 15073,   451, 19798,   425,    65,   878,  5635,  7570,\n","       15496,    65, 14554,  3917,    27,  1147, 15496,     1],\n","      dtype=int32), 'targets_pretokenized': b'{ mKeyListener.onResume(); }', 'targets': array([   20,   101,   342,  1128,    12,   141, 17628, 12329,    21,\n","           1], dtype=int32)}\n","{'inputs_pretokenized': b'BLOCK:private void updateMeetingPref(EMeetingPref meetingPref) { User user = usersController.getCurrentUser(); switch (meetingPref) { case ONLY_OWN_GENDER: <extra_id_0> case EVERYBODY: { user.setMeetingPref(getResources().getString(R.string.both)); break; } } } <CONST> <INV> void selectMeetingPreference(EMeetingPref) <OTH> void onCreate(Bundle), void onResume(), boolean onCreateOptionsMenu(Menu), boolean onOptionsItemSelected(MenuItem), int getLayoutResource(), void onClick(View), void onDeleteAccount()', 'inputs': array([17090,    78, 14566,    65,   611, 15730, 17862,   451,   676,\n","       15730, 17862,  1437, 17862,    91,    20,  1667,   500,    24,\n","        1454,  3055,    12,  1323, 28387, 12329,  1261,     4, 26185,\n","          27, 17862,    91,    20,   287, 14850,    35, 17167,    35,\n","       19842, 15507,    78, 32099,   287, 19590, 15234,    78,    20,\n","         500,    12,  2060, 15730, 17862,   451,  1323,  4592,  1927,\n","          12,  1323,   529,   451,   806,    12,  4635,    12, 15645,\n","          91,  4767,   513,   204,    21,    21,    21,    52, 28566,\n","        1302,    52,  3533,   744,  1302,    65,  1039, 15730,  8002,\n","         451,   676, 15730, 17862,    91,    52, 28174,  1302,    65,\n","          44,  2560,   451,  4211,   425,    65,    44, 17628, 15496,\n","         177,    44,  2560,  1044,  5774,   451,  5774,   425,   177,\n","          44,  1044,   847,  6677,   451,  9453,   425,    99, 15456,\n","         697, 15496,    65, 15477,   451,  1351,   425,    65,    44,\n","        2689,  3088,  1927,     1], dtype=int32), 'targets_pretokenized': b'{ user.setMeetingPref(user.getGender()); break; }', 'targets': array([   20,   500,    12,  2060, 15730, 17862,   451,  1988,    12,\n","        1323, 20701, 27706,   513,   204,    21,     1], dtype=int32)}\n","{'inputs_pretokenized': b'BLOCK:public static String getFragmentTitleForBook(Book book) { String str = null; if (book != null) { if (book.getTitle() != null) <extra_id_0> else { str = book.getName(); } } return str; } <CONST> <INV> <OTH> CharSequence getFragmentSubtitleForBook(Context, Book), CharSequence getError(Context, Book), CharSequence replaceWithLastActionError(Context, Book, CharSequence)', 'inputs': array([17090,    78,  2825,   190,    53, 21416,  4047,   608,  5360,\n","         451,  5360,   668,    91,    20,    53,  1047,    24,    70,\n","         204,    56,     4,  3190,   161,    70,    91,    20,    56,\n","           4,  3190,    12,  1323,  4047,  1927,   161,    70,    91,\n","       32099,   203,    20,  1047,    24,   668,    12,  1323,   186,\n","       12329,    21,    21,    40,  1047,   204,    21,    52, 28566,\n","        1302,    52,  3533,   744,  1302,    52, 28174,  1302,  8364,\n","       21416,  2664,  5563,   608,  5360,   451,   282,     9,  3133,\n","         425,  8364, 10699,   451,   282,     9,  3133,   425,  8364,\n","        1837,   449,  2844,  1001,  1168,   451,   282,     9,  3133,\n","           9,  8364,    91,     1], dtype=int32), 'targets_pretokenized': b'{ str = book.getTitle(); }', 'targets': array([   20,  1047,    24,   668,    12,  1323,  4047, 12329,    21,\n","           1], dtype=int32)}\n","{'inputs_pretokenized': b'BLOCK:public List<RuleClauseCode> codeFor(Node predicate) { if (!isCompiled) <extra_id_0> if (predicate.isVariable()) { return allRuleClauseCodes; } else { List<RuleClauseCode> codeList = predicateToCodeMap.get(predicate); if (codeList == null) { codeList = predicateToCodeMap.get(Node_RuleVariable.WILD); } return codeList; } } <CONST> LPRuleStore(List), LPRuleStore() <INV> List codeFor(TriplePattern) <OTH> void addAll(LPRuleStore), void tablePredicate(Node), boolean isIndexedPredicate(Node), boolean isTabled(TriplePattern), boolean isTabled(Node), void compileAll(), void doAddRemoveRule(Rule, boolean)', 'inputs': array([17090,    78,  2825,   163,  4298,  1704,  5297,  1259,  1302,\n","         927,   608,   451,   421,  5404,    91,    20,    56,     4,\n","         125,   660, 25358,    91, 32099,    56,     4, 30662,    12,\n","         660,  3002, 23620,    20,    40,    92,  1704,  5297, 12562,\n","         204,    21,   203,    20,   163,  4298,  1704,  5297,  1259,\n","        1302,   927,   277,    24,  5404,   379,  1259,   353,    12,\n","        1323,   451, 30662,  4767,    56,     4,  3927,   277,   126,\n","          70,    91,    20,   927,   277,    24,  5404,   379,  1259,\n","         353,    12,  1323,   451,   421,    35,  1704,  3002,    12,\n","       15081, 12813,  4767,    21,    40,   927,   277,   204,    21,\n","          21,    52, 28566,  1302, 13732,  1704,  1228,   451,   277,\n","         425, 13732,  1704,  1228,  1927,    52,  3533,   744,  1302,\n","         163,   927,   608,   451, 14457,  2452,    91,    52, 28174,\n","        1302,    65,  2599,   451,  9723,  1704,  1228,   425,    65,\n","         618,  3830,   451,   421,   425,   177,    28, 11595,  3830,\n","         451,   421,   425,   177,    28,   750,    34,   451, 14457,\n","        2452,   425,   177,    28,   750,    34,   451,   421,   425,\n","          65,  6390,  1218, 15496,    65,   123,  2937,  4940,  1704,\n","         451,  1704,     9,   177,    91,     1], dtype=int32), 'targets_pretokenized': b'{ compileAll(); }', 'targets': array([   20,  6390,  1218, 12329,    21,     1], dtype=int32)}\n","{'inputs_pretokenized': b'BLOCK:protected Path getOutline (String name, float width) { int index = getNameIndex (name); for (int i = 0; i < glyphnames.length; i++) { if (glyphnames[i] == index) <extra_id_0> } return readGlyph (charstringbase, 0); } <CONST> Type1CFont(String, PDFObject, PDFFontDescriptor) <INV> int getNameIndex(String), Path readGlyph(int, int), Path getOutline(char, float), void buildAccentChar(float, float, char, char, Path) <OTH> void printData(), int readNext(boolean), void readFNum(), int readInt(int), int readByte(), int getIndexSize(int), int getTableLength(int), Range getIndexEntry(int, int), void readDict(Range), int readCommand(boolean), void readEncodingData(int), void readGlyphNames(int), void readNames(int), void parse(), String safe(String), int calcoffset(int), String getSID(int), void parseGlyph(Range, Path, FlPoint)', 'inputs': array([17090,    78, 24154,  1327,    51, 19592,     4,   529,   187,\n","           9,  2383,  4199,    91,    20,    99,   579,    24,   467,\n","         591,     4,   766,  4767,    32,     4,  2886,   107,    24,\n","          88,   204,   107,    52,   188,    59,  3469,   766,     8,\n","          12,  7374,   204,   107, 15897,    91,    20,    56,     4,\n","         414,    59,  3469,   766,     8,  1242,   264,   827,   126,\n","         579,    91, 32099,    21,    40,   424, 20130,     4, 12471,\n","        4635,  4386,     9,    88,  4767,    21,    52, 28566,  1302,\n","        1498,   111,   323,  9822,   451,   529,     9,  5736,   587,\n","           9,  5736,  9822,  1565,    91,    52,  3533,   744,  1302,\n","          99,   467,   591,   451,   529,   425,  1327,   424, 20130,\n","         451,  2886,     9,    99,   425,  1327,    51, 19592,   451,\n","       12471,     9,  2383,   425,    65,   299, 15232,  1000,  4595,\n","         451, 12447,     9,  2383,     9,  1450,     9,  1450,     9,\n","        1327,    91,    52, 28174,  1302,    65,   948,   337, 15496,\n","          99,   424,  3691,   451, 14653,   425,    65,   424,   748,\n","        3427, 15496,    99, 10783,   451,  2886,   425,    99, 20954,\n","       15496,    99,  6046,   759,   451,  2886,   425,    99,  6101,\n","        1871,   451,  2886,   425,  5281,    51, 23817,   451,  2886,\n","           9,    99,   425,    65,   424, 17775,   451,  1907,   425,\n","          99,   424,  1408,   451, 14653,   425,    65,   424,  5055,\n","         337,   451,  2886,   425,    65,   424, 20130,  2715,   451,\n","        2886,   425,    65,   424,  2715,   451,  2886,   425,    65,\n","         743, 15496,    53,  1192,   451,   529,   425,    99,  8881,\n","       14043,   451,  2886,   425,    53,  6885,   440,   451,  2886,\n","         425,    65,   743, 20130,   451,  1907,     9,  1327,     9,\n","       14680,  2420,    91,     1], dtype=int32), 'targets_pretokenized': b'{ return readGlyph (charstringbase, i); }', 'targets': array([   20,    40,   424, 20130,     4, 12471,  4635,  4386,     9,\n","         107,  4767,    21,     1], dtype=int32)}\n"]}],"source":["nq_task = t5.data.TaskRegistry.get(\"block\")\n","ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": SEQ_LENGTH, \"targets\": SEQ_LENGTH})\n","print(\"A few preprocessed training examples...\")\n","for ex in tfds.as_numpy(ds.take(5)):\n","  print(ex)\n"]},{"cell_type":"markdown","metadata":{"id":"1LXgRmevgS6m"},"source":["### Evaluation\n","You can run the evaluation using the following cells.  \n","Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"cz1a1TxFNKmx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719681056,"user_tz":-120,"elapsed":6,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"edb150c2-045b-46a0-a523-c3781ba872b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<seqio.dataset_providers.Mixture at 0x7fb95795cbd0>"]},"metadata":{},"execution_count":20}],"source":["def _rate_num_input_examples(task):\n","  if \"train\" in task.splits:\n","    return float(task.num_input_examples(\"train\"))\n","  elif \"validation\" in task.splits:\n","    return float(task.num_input_examples(\"validation\"))\n","  else:\n","    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n","\n","\n","t5.data.MixtureRegistry.remove(\"all_tasks\")\n","t5.data.MixtureRegistry.add(\n","    \"all_tasks\",\n","    [\"construct\", \"token\", \"block\"],\n","    default_rate=_rate_num_input_examples\n","     #default_rate=1.0\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"_3Qx699vN302","executionInfo":{"status":"ok","timestamp":1652719685064,"user_tz":-120,"elapsed":4011,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n","import t5.models\n","\n","MODEL_SIZE = \"small\" \n","\n","# Set the folder where the checkpoints and all the others information will be writed\n","MODEL_DIR = BASE_DIR + '/T5_extension/finetuning'\n","\n","model_parallelism, train_batch_size, keep_checkpoint_max = {\n","    \"small\": (1, 256, 16000),\n","    \"base\": (2, 128, 8),\n","    \"large\": (8, 64, 4),\n","    \"3B\": (8, 16, 1),\n","    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n","\n","tf.io.gfile.makedirs(MODEL_DIR)\n","\n","model = t5.models.MtfModel(\n","    model_dir=MODEL_DIR,\n","    tpu=TPU_ADDRESS,\n","    tpu_topology=TPU_TOPOLOGY,\n","    model_parallelism=model_parallelism,\n","    batch_size=train_batch_size,\n","    learning_rate_schedule = slanted_triangular,\n","    sequence_length={\"inputs\": SEQ_LENGTH, \"targets\": SEQ_LENGTH},\n","    save_checkpoints_steps=5000,\n","    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n","    iterations_per_loop=100,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"yXye1wFNz8Vx","executionInfo":{"status":"ok","timestamp":1652719685065,"user_tz":-120,"elapsed":7,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":["# ## C.B.: Run only to create files.\n","\n","# model.batch_size = 512\n","# model.eval(\n","#     mixture_or_task_name=\"all_tasks\",\n","#     checkpoint_steps=-1 #evaluate only last checkpoint\n","# )"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"jyQY1MxTEFUx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652719781314,"user_tz":-120,"elapsed":96254,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}},"outputId":"b2e14a09-5278-45a1-c495-d3a4e63ed287"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:system_path_file_exists:gs://code-generation/T5_extension/finetuning/operative_config.gin\n","ERROR:root:Path not found: gs://code-generation/T5_extension/finetuning/operative_config.gin\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Using config: {'_model_dir': 'gs://code-generation/T5_extension/finetuning', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n","  rewrite_options {\n","    disable_meta_optimizer: true\n","  }\n","}\n","cluster_def {\n","  job {\n","    name: \"worker\"\n","    tasks {\n","      key: 0\n","      value: \"10.84.112.146:8470\"\n","    }\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.84.112.146:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.84.112.146:8470', '_evaluation_master': 'grpc://10.84.112.146:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fb957c8ab90>}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","INFO:tensorflow:Querying Tensorflow master (grpc://10.84.112.146:8470) for TPU system metadata.\n","INFO:tensorflow:Initializing TPU system (master: grpc://10.84.112.146:8470) to fetch topology for model parallelism. This might take a while.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -4101125011705012008)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4737261838237571255)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3131319847606687237)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 696592027694351864)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5714947412903155131)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -4889456088893363019)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9013171931536829076)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6857065041856659406)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7088556854547381923)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6109286485778332500)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -677526390279992602)\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:num_cores_per_replica: 1\n","INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n","INFO:tensorflow:num_replicas: 8\n","INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n","  [0 0 0 1]\n","  [1 0 0 0]\n","  [1 0 0 1]\n","  [0 1 0 0]\n","  [0 1 0 1]\n","  [1 1 0 0]\n","  [1 1 0 1]]]\n","INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n","\n"," [[0 0 0 1]]\n","\n"," [[1 0 0 0]]\n","\n"," [[1 0 0 1]]\n","\n"," [[0 1 0 0]]\n","\n"," [[0 1 0 1]]\n","\n"," [[1 1 0 0]]\n","\n"," [[1 1 0 1]]]\n","INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n","INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n","WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n","INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('d_ff', 'model'), ('batch', 'batch'), ('experts', 'batch'), ('ensemble', 'ensemble'), ('heads', 'model'), ('vocab', 'model')}\n","INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fb954034ed0>\n","WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n","WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n","WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n","INFO:tensorflow:Create pnum_tensor\n","INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n","INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n","INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n","INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n","INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n","INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n","INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n","INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n","INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n","INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n","INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n","INFO:tensorflow:    encoder/final_layer_norm/scale\n","INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n","INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n","INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n","INFO:tensorflow:    decoder/final_layer_norm/scale\n","INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n","INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n","INFO:tensorflow:Counters:\n","allconcat: 2.1e+06\n"," allconcat/0: 2.1e+06\n","  allconcat/0/reshape_op: 2.1e+06\n","allreduce: 8\n"," allreduce/[0]: 8\n","  allreduce/[0]/reduce_op: 8\n","einsum: 1.35e+13\n","einsum_unique: 1.35e+13\n","output: 1.35e+11\n"," output/AddOperation: 3.44e+10\n"," output/BinaryOpWithBroadcasting: 4.56e+08\n"," output/Constant: 8.05e+08\n"," output/EinsumOperation: 3.07e+10\n"," output/ImportOperation: 1.05e+06\n"," output/MinMaxOperation: 3.79e+07\n"," output/OneHotOperation: 9.23e+09\n"," output/RangeOperation: 8.19e+03\n"," output/ReduceOperation: 4.19e+07\n"," output/ReshapeOperation: 6.92e+09\n"," output/ScalarAddOperation: 5.45e+07\n"," output/ScalarMultiplyOperation: 5.75e+08\n"," output/ShiftOperation: 1.31e+05\n"," output/SlicewiseOperation: 4.12e+10\n"," output/StackedVariable: 1.35e+05\n"," output/StopGradient: 9.66e+09\n"," output/UnstackOperation: 1.35e+05\n"," output/Variable: 4.84e+08\n"," output/WhileLoopOperation: 8.05e+08\n","output_unique: 1.33e+11\n"," output_unique/AddOperation: 3.43e+10\n"," output_unique/BinaryOpWithBroadcasting: 4.12e+08\n"," output_unique/Constant: 8.05e+08\n"," output_unique/EinsumOperation: 3.05e+10\n"," output_unique/ImportOperation: 1.31e+05\n"," output_unique/MinMaxOperation: 4.85e+06\n"," output_unique/OneHotOperation: 8.52e+09\n"," output_unique/RangeOperation: 1.02e+03\n"," output_unique/ReduceOperation: 4.19e+07\n"," output_unique/ReshapeOperation: 6.91e+09\n"," output_unique/ScalarAddOperation: 1.05e+07\n"," output_unique/ScalarMultiplyOperation: 4.87e+08\n"," output_unique/ShiftOperation: 1.31e+05\n"," output_unique/SlicewiseOperation: 4.09e+10\n"," output_unique/StackedVariable: 1.69e+04\n"," output_unique/StopGradient: 9.66e+09\n"," output_unique/UnstackOperation: 1.69e+04\n"," output_unique/Variable: 6.05e+07\n"," output_unique/WhileLoopOperation: 8.05e+08\n","variables: 6.05e+07\n"," variables/trainable: 6.05e+07\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:TPU job name worker\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from gs://code-generation/T5_extension/finetuning/model.ckpt-900000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:825: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Prefer Variable.assign which has equivalent behavior in 2.X.\n","INFO:tensorflow:Starting infeed thread controller.\n","INFO:tensorflow:Starting outfeed thread controller.\n","INFO:tensorflow:Initialized dataset iterators in 0 seconds\n","INFO:tensorflow:Before copy master to slices.\n","INFO:tensorflow:Done with copy master to slices.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Outfeed finished for iteration (0, 0)\n","INFO:tensorflow:decoded 0: b'TOKEN:public static Analyzer fromSpec(final JSONObject json, final String analyzerKey) throws JSONException { JSONObject spec = json.optJSONObject(analyzerKey<extra_id_0> if (spec != null) { return getAnalyzer(spec); } else { return getAnalyzer(json.optString(analyzerKey, Constants.DEFAULT_ANALYZER)); } }'\n","INFO:tensorflow:            -> );\n","INFO:tensorflow:decoded 1: b'TOKEN:public static Analyzer getAnalyzer(final String str) throws JSONException { final String[] parts = str.split(\":\", 2); final String name = parts[0].toUpperCase(); final String args = parts.length == 2 <extra_id_0> return Analyzers.valueOf(name).newAnalyzer(args); }'\n","INFO:tensorflow:            -> ;\n","INFO:tensorflow:decoded 2: b'TOKEN:private static List<ParamSpec> getParamSpecs(JSONArray jsonParams) throws ParameterException, JSONException { final List<ParamSpec> paramSpecs = new ArrayList<>(); if (jsonParams != null) { for (int i = 0; i < jsonParams.length()<extra_id_0> paramSpecs.add(getParamSpec(jsonParams.getJSONObject(i))); } } return paramSpecs; }'\n","INFO:tensorflow:            -> ; i++) {\n","INFO:tensorflow:decoded 4: b'TOKEN:public Analyzer newAnalyzer(final JSONObject json) throws JSONException { Analyzer analyzer = fromSpec(json); int min = json.optInt(\"min\", NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE<extra_id_0> int max = json.optInt(\"max\", NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE); return new NGramAnalyzer(analyzer, min, max); }'\n","INFO:tensorflow:            -> );\n","INFO:tensorflow:decoded 8: b'TOKEN:protected Query getRangeQuery(final String field, final String lower, final String upper, <extra_id_0> throws ParseException { return new TypedField(field).toRangeQuery(lower, upper, lowerInclusive, upperInclusive); }'\n","INFO:tensorflow:            -> final String lowerInclusive, final String upperInclusive)\n","INFO:tensorflow:decoded 16: b'TOKEN:private long toLong(final Object obj) { if (obj instanceof Number) { return ((Number) obj).longValue(); } return <extra_id_0> }'\n","INFO:tensorflow:            -> -1;\n","INFO:tensorflow:decoded 32: b'TOKEN:public static void fill(Bucket bucket, long length) throws IOException { OutputStream os = null; try { os = bucket.getOutputStreamUnbuffered(); FileUtil.fill(os, length); } finally { if(os <extra_id_0> } }'\n","INFO:tensorflow:            -> != null) { IoUtil.close(os); }\n","INFO:tensorflow:decoded 64: b'TOKEN:private synchronized void addStream(Closeable stream) { // BaseFileBucket is a very common object, and often very long lived, // so we need to minimize memory usage even at the cost of frequent allocations. if(streams == null) streams = new Vector<extra_id_0> streams.add(stream); }'\n","INFO:tensorflow:            -> >();\n","INFO:tensorflow:decoded 128: b'TOKEN:private int checkImportant(ParsedWord[] words) { if(words.length == 0) return 0; if(words.length >= 1 && words[words.length-1] instanceof SimpleParsedWord) { if(((SimpleParsedWord)words[words.length-1]).original.equalsIgnoreCase(\"!important\")) return 1; } if(words.length >= 2 && words[words.length-1] instanceof ParsedIdentifier && words[words.length-2] instanceof SimpleParsedWord) { if(((SimpleParsedWord)words[words.length-2]).original.equals(\"!\") <extra_id_0><extra_id_0> ((ParsedIdentifier)words[words.length-1]).original.equalsIgnoreCase(\"important\")) return 2; } return 0; }'\n","INFO:tensorflow:            -> ;\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 256: b'TOKEN:private void writeCheckBlocks(byte[][] checkBlocks) throws IOException { RAFLock lock = parent.lockRAF(); try { for(int i=0;i<checkBlocks.length;i++) writeCheckBlock(i, checkBlocks<extra_id_0> } finally { lock.unlock(); } }'\n","INFO:tensorflow:            -> [i]\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 512: b'TOKEN:public synchronized void add(int num) { int x = binarySearch(num); if(x >= 0) { throw new IllegalArgumentException(); // already exists } <extra_id_0> x = -x-1; push(num, x); }'\n","INFO:tensorflow:            -> else {\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 1024: b'TOKEN:NestedAnnotation(String name, AnnotationInstance value) { super(name<extra_id_0> this.value = value; }'\n","INFO:tensorflow:            -> );\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 2048: b'TOKEN:public MoneyAmountStyle withGroupingStyle(GroupingStyle groupingStyle) { MoneyFormatter.checkNotNull(groupingStyle, \"groupingStyle\"); if (this.groupingStyle == groupingStyle) { return this; } return new MoneyAmountStyle( <extra_id_0> positiveCharacter, negativeCharacter, decimalPointCharacter, groupingStyle, groupingCharacter, groupingSize, extendedGroupingSize, forceDecimalPoint, absValue); }'\n","INFO:tensorflow:            -> controlContext,\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 4096: b'TOKEN:public void flush() throws IOException { if (_out != null) { if (_outPtr > 0) { _out.write(_outBuffer, 0, _outPtr); _outPtr = 0; } <extra_id_0> } }'\n","INFO:tensorflow:            -> else { _out = null; }\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:decoded 8192: b'TOKEN:public boolean isList(String path) { Object val <extra_id_0> return val instanceof List; }'\n","INFO:tensorflow:            -> = get(path);\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n","INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n","INFO:tensorflow:Stop infeed thread controller\n","INFO:tensorflow:Shutting down InfeedController thread.\n","INFO:tensorflow:InfeedController received shutdown signal, stopping.\n","INFO:tensorflow:Infeed thread finished, shutting down.\n","INFO:tensorflow:infeed marked as finished\n","INFO:tensorflow:Stop output thread controller\n","INFO:tensorflow:Shutting down OutfeedController thread.\n","INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n","INFO:tensorflow:Outfeed thread finished, shutting down.\n","INFO:tensorflow:outfeed marked as finished\n","INFO:tensorflow:Shutdown TPU system.\n","INFO:tensorflow:prediction_loop marked as finished\n","INFO:tensorflow:prediction_loop marked as finished\n"]}],"source":["# we used model.predict function (setting beam_size)\n","\n","vocabulary_predict=get_default_vocabulary()\n","\n","input_file = BASE_DIR + '/T5_extension/finetuning/predict/inputs.txt'\n","output_file = BASE_DIR + '/T5_extension/finetuning/predict/predictions.txt'\n","\n","model.predict(input_file=input_file, output_file=output_file,\n","              checkpoint_steps=-1, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"fTr15bwE6YY-","executionInfo":{"status":"ok","timestamp":1652719781314,"user_tz":-120,"elapsed":11,"user":{"displayName":"Cristian Buratti","userId":"16128402122774352339"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"evaluatetesting.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}